{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HST WFC3/UVIS Reduction and Dark Correction for a Set of Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook describes the step-by-step procedure required to improve the reduction of darks and include these in the reduction of a set of Hubble Space Telescope (HST) Wide Field Camera 3 (WFC3)/UV-Visible (UVIS) observations. This is based on the Space Telescope Science Institute (ST/STScI) standard WFC3/UVIS darks reduction pipeline as copied from GitHub 19th April 2019. All changes made to the ST codes should be denoted by \"LP\" in the comments. Written by Laura Prichard, April–September 2019.\n",
    "\n",
    "___________________\n",
    "# Setup\n",
    "\n",
    "This notebook should come in a darks reduction package (`hst_wfc3_uvis_reduction/`) in the directory `hst_wfc3_uvis_reduction/darks_codes/lp_darks/`. In `darks_codes/` is: \n",
    "\n",
    "    - st_darks/ – the ST standard darks reduction copied from GitHub 19th April 2019.\n",
    "    - lp_darks/ – copy of the st_darks/ directory that was edited.\n",
    "    - mr_darks/ – copy of Marc Rafelski's codes and reference tables some of which were implemented in the lp_darks/ version of the ST pipeline.\n",
    "    \n",
    "In `darks_codes/lp_darks/` is the following: \n",
    "\n",
    "    - the CTE correction code directory (cal_uvis_make_ctecorr_darks/), \n",
    "    - the directory of the main codes for the pipeline (cal_uvis_make_darks/, main code is cal_uvis_make_darks.py), \n",
    "    - a folder for reference tables i.e. dark_lookup.txt (ref_files/),\n",
    "    - an empty folder for terminal outputs for the codes (logs/),\n",
    "    - a code to download data with astroquery and organize files ready for reduction (download_data.py), \n",
    "    - a code to CTE correct science data (ctecorr_scidata.py),\n",
    "    - and this notebook (darks_reduction.ipynb). \n",
    "\n",
    "The darks codes are kept in a root directory `hst_wfc3_uvis_reduction/` along with the data directory e.g., `darks_data/`. This should contain three more directories (all empty), one for the raw data (e.g., `raw_darks/`), reduced data (e.g., `red_darks/`) and a directory for STScI calibration files (e.g., `st_calib/`, more info below on this). These will be in the `hst_wfc3_uvis_reduction/darks_data/` directory, otherwise they should be made should be made in a location of choice but be kept seperate from the code directory, e.g.:\n",
    "\n",
    "    - darks_data/red_darks/ – location for the reduced data pipeline outputs\n",
    "    - darks_data/raw_darks/ – location of the raw data\n",
    "    - darks_data/st_calib/ – location of STScI calibration files used by the pipeline (more info below)\n",
    "\n",
    "\n",
    "\n",
    "**1) Set directories**\n",
    "\n",
    "They should be defined and made if they don't exist. An example of this is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit and run this to define and make the following directories\n",
    "import os\n",
    "\n",
    "# Setting path names\n",
    "DARK_ROOT = \"/user/lprichard/hst_wfc3_uvis_reduction\"  #EDIT! Root directory for whole of the darks codes and data\n",
    "CODE_DIR = os.path.join(DARK_ROOT, 'darks_codes')  #Location of the darks_codes directories that come with this darks reduction package\n",
    "DAT_DIR = os.path.join(DARK_ROOT, 'darks_data')    #Data directory to contain the following sub directories\n",
    "RAW_DIR = os.path.join(DAT_DIR, 'raw_darks')       #Raw data directory\n",
    "RED_DIR = os.path.join(DAT_DIR, 'red_darks')       #Reduced data directory\n",
    "CAL_DIR = os.path.join(DAT_DIR, 'st_calib')        #ST calibration files directory\n",
    "\n",
    "print('DARK_ROOT =', DARK_ROOT)\n",
    "print('CODE_DIR =', CODE_DIR)\n",
    "print('DAT_DIR =', DAT_DIR)\n",
    "print('RAW_DIR =', RAW_DIR)\n",
    "print('RED_DIR =', RED_DIR)\n",
    "print('CAL_DIR =', CAL_DIR)\n",
    "\n",
    "# Making data directories if they don't exist\n",
    "if not os.path.exists(DAT_DIR): \n",
    "    os.makedirs(DAT_DIR, 0o774)\n",
    "if not os.path.exists(RAW_DIR): \n",
    "    os.makedirs(RAW_DIR, 0o774)\n",
    "if not os.path.exists(RED_DIR): \n",
    "    os.makedirs(RED_DIR, 0o774)\n",
    "if not os.path.exists(CAL_DIR): \n",
    "    os.makedirs(CAL_DIR, 0o774)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Add the codes directory to your PYTHONPATH**\n",
    "\n",
    "Add the folder *above* `cal_uvis_make_ctecorr_darks/` and `cal_uvis_make_darks/` to your PYTHONPATH,\n",
    "\n",
    "    e.g. in ~/.bashrc `export PYTHONPATH=\"[CODE_DIR]/lp_darks:$PYTHONPATH\"`\n",
    "\n",
    "Initialize each directory if not done already, in `DARK_ROOT/darks_codes/lp_darks/cal_uvis_make_ctecorr_darks/` and `DARK_ROOT/darks_codes/lp_darks/cal_uvis_make_darks/`, do `touch __init__.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Get STScI standard calibration files**\n",
    "\n",
    "Copies of the STScI standard calibration files used in the reduction are required. These should be put in the `st_calib/` directory (or another if preferred). Set this location of the calibration files directory as an input to the main darks reduction code (`cal_uvis_make_darks.py`) using the flag `-c|--cal_dir`.\n",
    "    \n",
    "Get the latest copy of the calibration files (from Catherine Martlin - cmartlin@stsci.edu, or any of the WFC3 team with access to the files below) and put each in `st_calib/` (or your preferred location):\n",
    "\n",
    "    /grp/hst/wfc3k/uvis_darks/exclude.list\n",
    "    /grp/hst/wfc3k/uvis_darks/crr_for_dark.fits\n",
    "    /grp/hst/wfc3k/uvis_darks/crr_for_hotpix.fits\n",
    "    /grp/hst/wfc3b/calibration/history.txt\n",
    "    \n",
    "According to Catherine, history.txt is the only one that is regularly updated and is done by Sylvia Baggett (WFC3 Branch Manager) around every month with both anneal (publicly available) AND lockups (not public), making this file internal to ST. A new copy of this file and the others (to be sure) are required regularly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________\n",
    "# Download and Organize Darks\n",
    "\n",
    "**4) Get anneal cycle dates**\n",
    "\n",
    "Get the dates of the observations in question (e.g. from MAST https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html) and then find the WFC3 anneal cycles that span the dates of the observations. From http://www.stsci.edu/hst/instrumentation/wfc3/performance/monitoring/complete-anneal-history (try Safari or other browser if not working with Chrome, email WFC3 team member if not up to date), get a list of the dates & times for all anneal cycles that your spans your data, e.g. \n",
    "\n",
    "    58561.85943287  2019.078 20:37:35 Mar 19 anneal\n",
    "    \n",
    "This is the start date (MJD YEAR.DAY HH:MM:SS, Month YY anneal) of the anneal cycle. The anneal cycle ends the file before that of the next listed anneal date and time, e.g.:\n",
    "\n",
    "    58590.47559028  2019.107 11:24:51 Apr 17  anneal\n",
    "    \n",
    "Get the start/end anneal cycle Modified Julien Date (MJD, first value) for ONE anneal cycle at a time as inputs to the codes below.\n",
    "\n",
    "If wanting to process darks from the **current** anneal cycle, the anneal start date should still be given, and the anneal end date can be now. This is generated in MJD using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.time import Time\n",
    "\n",
    "now = Time(Time.now(), format='iso').mjd\n",
    "\n",
    "print('MJD Now:', now)\n",
    "\n",
    "# Or can convert the YEAR.DAY HH:MM:SS format to MJD with the following\n",
    "in_date = '2019.107 11:24:51'\n",
    "\n",
    "# Calculate MJD\n",
    "in_date = in_date.replace('.', ':').replace(' ', ':')\n",
    "out_date = Time(in_date, format='yday').mjd\n",
    "print('MJD of input date:', out_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5) Download data with astroquery and organize**\n",
    "\n",
    "Then run the following code that makes directories, downloads data with astroquery and sorts raw dark files ready for CTE corrections using `hst_wfc3_uvis_reduction/darks_codes/lp_darks/download_data.py`. Run using the following command in `hst_wfc3_uvis_reduction/darks_codes/lp_darks/`:\n",
    "\n",
    "        python download_data.py [-t|--type] [-s|--data_start] [-e|--data_end] [-p|--proposal_id] [-r|--raw_dir] [-d|--download] [-l|--dload_date]\n",
    "\n",
    "Required:\n",
    "    \n",
    "    [-t|--type] – String, the type of data to be downloaded, either ``dark`` for raw darks or ``science`` for raw science data. ``-s --data_start`` and ``-e --data_end`` must be set to the anneal start and end (or present) dates if --type==``dark``. ``-p --proposal_id`` must be set if --type==``science``, and start and end dates within that proposal ID are optional.\n",
    "    [-s|--data_start] – String/float, required if --type==``dark``: MJD value of start date of ONE anneal cycle to at least 6 d.p. from the webpage above (Step 4). Optional if --type==``science``: science data start date if a section of a proposal's data is to be downloaded rather than the whole program.\n",
    "    [-e|--data_end] – String/float, required if --type==``dark``: MJD value of end date of ONE anneal cycle to at least 6 d.p. from the webpage above (Step 4). Optional if type==``science``: science data end date if a section of a proposal's data is to be downloaded rather than the whole program. All files up to but NOT INCLUDING the end date are selected.\n",
    "    [-p|--proposal_id] – String, proposal ID of the science data to be downloaded, REQUIRED if --type==``science``. NOT NEEDED needed for darks download.\n",
    "    [-r|--raw_dir] – String, path to the directory where raw data should be stored. A directory for each anneal cycle will be made within that, along with seperate sub-folders for downloaded, raw and CTE corrected darks. No trailing slash \"/\".\n",
    "    \n",
    "Optional:\n",
    "\n",
    "    [-d|--download] – Flag, is ``True`` if provided, ``False`` otherwise and is required if you want astroquery to download the raw files.\n",
    "    [-l|--dload_date] – String, download date, should be set if -d|--download is not set as this points to the directory where the data were downloaded which is timestamped. Should be in the format ``YYYYMonDD`` e.g. ``2019Aug13``.\n",
    "    \n",
    "Execution of this script will create the following file tree:\n",
    "\n",
    "    <anneal_date:YYYYMMMDD>anneal_rawdarks_aquery<download_date:YYYYMMMDD>/\n",
    "        ctecorr_darks/\n",
    "        mastDownload/HST/  (created by the astroquery download command)    \n",
    "            id**/          (creates ID specific folders with the raw files in)\n",
    "        raw_darks/         (folder for the raw darks combined from their individual download directories)\n",
    "    \n",
    "An example of using the code in a terminal is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ************************************************************\n",
    "# Example of inputs\n",
    "# -t|type = 'dark'\n",
    "# -s|--anneal_start = '58676.18376157'\n",
    "# -e|--anneal_end = '58694.25990740'\n",
    "# -r|--raw_dir = '/user/lprichard/hst_wfc3_uvis_reduction/darks_data/raw_darks'\n",
    "\n",
    "# Set the following flag which will set download to ``True``\n",
    "# -d|--download\n",
    "# OTHERWISE set dload_date to point to a directory of data downloaded \n",
    "# on this date to do just the file organization and copying\n",
    "# -l|--dload_date = '2019Aug13'\n",
    "# ************************************************************\n",
    "\n",
    "# Move into codes directory and start screen\n",
    "# cd /user/lprichard/hst_wfc3_uvis_reduction/darks_codes/lp_darks\n",
    "# screen -S darks_dload\n",
    "\n",
    "# Use the following command in a terminal, the \"mode\" and \"now\" definitions ahead are for the log \n",
    "# name that the terminal output is piped to which is called at the end of the commnad. \"pdb\" ipython command is for debugging.\n",
    "# Set to download\n",
    "now=$(date +\"%m_%d_%Y\") && ipython --pdb -c \"%run download_data.py  -t 'dark' -s '58676.18376157' -e '58694.25990740' \\\n",
    "    -r '/user/lprichard/hst_wfc3_uvis_reduction/darks_data/raw_darks' -d\" 2>&1 | tee /user/lprichard/hst_wfc3_uvis_reduction/darks_codes/lp_darks/logs/log_aquery_$now.txt\n",
    "# OR for file organization of downloaded data\n",
    "now=$(date +\"%m_%d_%Y\") && ipython --pdb -c \"%run download_data.py  -t 'dark' -s 58676.18376157 -e 58694.25990740 \\\n",
    "    -r '/user/lprichard/hst_wfc3_uvis_reduction/darks_data/raw_darks' -l '2019Aug13'\" 2>&1 | tee /user/lprichard/hst_wfc3_uvis_reduction/darks_codes/lp_darks/logs/log_aquery_$now.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________\n",
    "# CTE Correct Darks\n",
    "\n",
    "**6) Check WFC3 CTE correction executable**\n",
    "\n",
    "____________________________\n",
    "NOTE: The following method is based on an old CTE correction code. As of Feb 2020, STScI are testing a new CTE correction code. Check back to the GitHub repository or the STScI website for updates prior to running this step in case this new code has been released.\n",
    "____________________________\n",
    "\n",
    "Using the edited version of `cal_uvis_make_ctecorr_darks.py`\n",
    "\n",
    "    hst_wfc3_uvis_reduction/darks_codes/lp_darks/cal_uvis_make_ctecorr_darks/cal_uvis_make_ctecorr_darks.py\n",
    "    \n",
    "This does not depend on Quicklook (as used by STScI) and the files are organized using information in the header (rather than the default STScI file organization). This code is dependent on the standard CTE corrections code written by Jay Anderson and available here:\n",
    "\n",
    "http://www.stsci.edu/hst/instrumentation/wfc3/software-tools/cte-tools\n",
    "\n",
    "In a software directory of choice, download the file using `copy link address` on the above web page \n",
    "    \n",
    "    e.g. cd /user/lprichard/software\n",
    "    wget http://www.stsci.edu/~jayander/X/EXPORT_WFC3UV_CTE/wfc3uv_ctereverse.F\n",
    "    \n",
    "Following instructions on the web page, then do the following:\n",
    "\n",
    "    gfortran wfc3uv_ctereverse.F -o wfc3uv_ctereverse.e\n",
    "    \n",
    "WARNING, the code must then be run on the computer that the software is compiled on. The SOFTWARE_DIR is a required input to the code.\n",
    "    \n",
    "The webpage says the following \n",
    "\n",
    "    \"Then you can run the program.  This particular routine \n",
    "     insists that all the exposures be in the same directory.  \n",
    "     The executable can be in a different directory, but the\n",
    "     images you're reading in and operating on *must* be in \n",
    "     your current directory.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7) Run CTE correction**\n",
    "\n",
    "Calling sequence of the CTE correction code:\n",
    "\n",
    "    python cal_uvis_make_ctecorr_darks.py [-c|--ctecorr_dir] [-r|--rwd_dir] [-s|--software_dir]\n",
    "        \n",
    "Required:\n",
    "\n",
    "    [-c|--ctecorr_dir] -- String, path to the output CTE corrected data directory (as made in download_data.py to [raw_dir]/[anneal_dir]/ctecorr_darks, no trailing slash \"/\".\n",
    "    [-r|--rwd_dir] -- String, path to the input raw data directory (all files in one folder as done in previous step with download_data.py to [raw_dir]/[anneal_dir]/raw_darks), no trailing slash \"/\".\n",
    "    [-s|--software_dir] -- String, path to the compiled CTE correction code ./wfc3uv_ctereverse.e, no trailing slash \"/\".\n",
    "    \n",
    "The following is an example of running the code in a terminal:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ************************************************************\n",
    "# Example of inputs\n",
    "# -c|--ctecorr_dir = '/user/lprichard/hst_wfc3_uvis_reduction/darks_data/raw_darks/2019Mar19anneal_rawdarks_aquery2019Aug13/ctecorr_darks'\n",
    "# -r|--rwd_dir = '/user/lprichard/hst_wfc3_uvis_reduction/darks_data/raw_darks/2019Mar19anneal_rawdarks_aquery2019Aug13/raw_darks'\n",
    "# -s|--software_dir = '/user/lprichard/software' \n",
    "# ************************************************************\n",
    "\n",
    "# Move into codes directory and start screen, should take ~1hour depending on processing power\n",
    "# cd /user/lprichard/hst_wfc3_uvis_reduction/darks_codes/lp_darks/cal_uvis_make_ctecorr_darks\n",
    "# screen -S ctecorr\n",
    "\n",
    "# Use the following command in a terminal, the \"mode\" and \"now\" definitions ahead are for the log \n",
    "# name that the terminal output is piped to which is called at the end. \"pdb\" ipython command is for debugging.\n",
    "now=$(date +\"%m_%d_%Y\") && ipython --pdb -c \"%run cal_uvis_make_ctecorr_darks.py \\\n",
    "    -c '/user/lprichard/hst_wfc3_uvis_reduction/darks_data/raw_darks/2019Mar19anneal_rawdarks_aquery2019Aug13/ctecorr_darks' \\\n",
    "    -r '/user/lprichard/hst_wfc3_uvis_reduction/darks_data/raw_darks/2019Mar19anneal_rawdarks_aquery2019Aug13/raw_darks' \\\n",
    "    -s '/user/lprichard/software'\" 2>&1 | tee /user/lprichard/hst_wfc3_uvis_reduction/darks_codes/lp_darks/logs/log_ctecorr_$now.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________\n",
    "# Update Headers to Point to Right Calibration Files\n",
    "\n",
    "**If required**\n",
    "\n",
    "Case specific: i.e. if you want to use a new bias file, check in the headers if the calibration files are as expected. If not, update them using something like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import astropy.io.fits as fits\n",
    "\n",
    "# Move into CTE correction directory\n",
    "os.chdir(CTE_CORR_DIR)\n",
    "\n",
    "# For each file in there, check the headers and update:\n",
    "for f in glob.glob('*rac.fits'):\n",
    "    print(f)\n",
    "    \n",
    "    # Open image and get the header\n",
    "    hdul = fits.open(f, 'update')\n",
    "    hdr = hdul[0].header\n",
    "    \n",
    "    # Get and update bias\n",
    "    print(\"Updating \", hdr['BIASFILE'], \"to iref$38c19068i_bia.fits\")\n",
    "    hdr['BIASFILE'] = 'iref$38c19068i_bia.fits'    #Changed from old bias file 'iref$37n1502si_bia.fits'\n",
    "    \n",
    "    # Save changes\n",
    "    hdul.flush()\n",
    "    hdul.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________\n",
    "# Reduce Darks\n",
    "\n",
    "**8) Get anneal dates as inputs**\n",
    "\n",
    "As in step 4), get the dates of the observations in question (e.g. from MAST https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html) and then find the anneal cycles needed for those data from http://www.stsci.edu/hst/instrumentation/wfc3/performance/monitoring/complete-anneal-history (try Safari or other browser if not working with Chrome, email WFC3 team member if not up to date).\n",
    "\n",
    "Get start and end dates/times for **ONE** anneal cycle at a time in the form ``YYYYMMDD-HH:MM:SS``. An anneal cycle is labeled by its *start* date, i.e. March 19 2019 anneal has format `58561.85943287 2019.078 20:37:35 19-Mar anneal` on the webpage, this translates to an `--anneal_date` input of `20190319-20:37:35`. The appropriate `--endtime` of this anneal cycle is the start date of the next anneal cycle (April 17 2019) as all files *before* this time are included in the anneal cycle. So from the webpage: `58590.47559027 2019.107 11:24:51 17-Apr anneal` tanslates to `--endtime` input of `20190417-11:24:50`.\n",
    "\n",
    "Again, if wanting to process darks from the **current** anneal cycle, the anneal start date should still be given, and the anneal end date can be now. This is generated in the right format below. For convenience, you can convert the start and end times to the required input format using the Modified Julien Date (MJD; values from link above) using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.time import Time\n",
    "\n",
    "# ------------------------------\n",
    "# INPUT\n",
    "# Set the input anneal cycle start and end MJD dates\n",
    "anneal_start = 58561.85943287\n",
    "anneal_end = 58590.47559027\n",
    "# ------------------------------\n",
    "\n",
    "# Converting MJD to YYYYMMDD-HH:MM:SS format\n",
    "# Anneal start date\n",
    "t_start = Time(anneal_start, format='mjd')\n",
    "an_start = t_start.strftime('%Y%m%d-%H:%M:%S')\n",
    "print('Anneal start date: ', an_start)\n",
    "\n",
    "# Anneal end date\n",
    "t_end = Time(anneal_end, format='mjd')\n",
    "an_end = t_end.strftime('%Y%m%d-%H:%M:%S')\n",
    "print('Anneal end date: ', an_end)\n",
    "\n",
    "# Anneal end date of now if in present cycle\n",
    "now = Time(Time.now(), format='iso').mjd\n",
    "t_now = Time(now, format='mjd')\n",
    "an_now = t_now.strftime('%Y%m%d-%H:%M:%S')\n",
    "print('Now end date: ', an_now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If running the code in mode (-m) \"prod\"**\n",
    "\n",
    "This mode is currently the default used by STScI (although developments to change this default are underway as of Feb 2020). With this code, it is advised to use the ``dev`` mode which improves the quality of the darks significantly. ``dev`` takes darks from the concurrent anneal cycle to replace good pixels from, rather than from the previous anneal cycle (i.e. ``prod`` mode). This is usually done just to save time as one has to wait for the anneal cycle to end before processing data can begin. \n",
    "\n",
    "If you wish to use the code using the ``prod`` mode then this is possible but you have to retreive the masterdark from the previous anneal cycle in order to do so. These are stored in the following directory and can be requested from the WFC3 team:\n",
    "\n",
    "    /grp/hst/wfc3k/uvis_darks/masterdarks/\n",
    "    \n",
    "Masterdarks have the following naming structure, where the below file is for e.g., Feb 21, 2019, the start date of the previous anneal cycle to that being run, e.g., March 19, 2019\n",
    "\n",
    "    masterdark_2019-02-21_ctecorr.fits\n",
    "\n",
    "These should be saved locally to the `masterdarks/` directory that should be made *within the reduction directory prior to running the code* and this masterdark placed there e.g.,\n",
    "\n",
    "    /user/lprichard/hst_wfc3_uvis_reduction/darks_data/red_darks/masterdarks\n",
    "    \n",
    "NOTE: If running in ``dev`` mode, the `masterdarks/` directory will be made automatically in the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9) Run the code**\n",
    "\n",
    "Calling sequence of the darks reduction code:\n",
    "\n",
    "    python cal_uvis_make_darks.py [-a|--anneal_date] [-e|--endtime]\n",
    "        [-c|--ctecorr] [-p|--postflash] [-m|--mode] [-r|--red_dir]\n",
    "        [-d|--ctecorr_dir] [-l|--cal_dir] [-i|--iref_dir] [-f|--fitpix]\n",
    "        \n",
    "Required:\n",
    "\n",
    "    [-a|--anneal_date] -- String, start date for ONE anneal in format generated in Step 8 from MJD date.\n",
    "    [-e|--endtime] -- String, end date for ONE anneal in format generated in Step 8 from MJD date. OR today's date if within the anneal cycle to be reduced.\n",
    "    [-r|--red_dir] -- String, path to reduction directory for outputs and reduced data, no trailing slash \"/\". A directory for each anneal cycle is made within that.\n",
    "    [-d|--ctecorr_dir] -- String, path to raw CTE corrected data directory, no trailing slash \"/\".\n",
    "    [-l|--cal_dir] -- String, path to STScI calibration files needed for reduction (Step 3), no trailing slash \"/\".\n",
    "\n",
    "Optional:\n",
    "\n",
    "    [-c|--ctecorr] -- Flag, advised with this version. Sets CTE corrected to ``True``, use for data that was CTE corrected prior to running code.\n",
    "    [-p|--postflash] -- Flag, advised. Sets postflash to ``True``, postflashed darks will be used.\n",
    "    [-m|--mode] -- String, method of replacing pixels in the superdarks, ``dev`` takes pixels from the concurrent anneal cycle's masterdark, ``prod`` takes pixels from the previous anneal's masterdark. Advised ``dev``, default ``dev``, other option ``prod`` (which is the current ST default).\n",
    "    [-i|--iref_dir] -- String, path to IREF files. Default ``/grp/hst/cdbs/iref``, set if different. \n",
    "    [-f|--fitpix] -- Flag, advised. Option to create a hot pixel threshold function by row number to find the number of hot pixels to match that close to the read out, i.e. increases completeness of identifying hot pixels. The value is ``True`` (i.e. fit hot pixels with a threshold function) if provided and ``False`` (i.e. don't fit hot pixels with a threshold function) if not provided, in which case a constant hot pixel threshold (0.015 e-/s) will be used (standard in the STScI pipeline).\n",
    "    \n",
    "The following is an example of running the code in a terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *******************************************************************************\n",
    "# Example of inputs\n",
    "# Must be run for one anneal cycle at a time\n",
    "# -a|--anneal_date = '20190319-20:37:35'\n",
    "# -e|--endtime = '20190417-11:24:51'\n",
    "# -m|--mode = 'dev'\n",
    "\n",
    "# Directories set by user\n",
    "# -r|--red_dir = '/user/lprichard/hst_wfc3_uvis_reduction/darks_data/red_darks'    #Reduction directory for all output files, advised not to put with data\n",
    "# -d|--ctecorr_dir = '/user/lprichard/hst_wfc3_uvis_reduction/darks_data/raw_darks/2019Mar19anneal_rawdarks_aquery2019Aug13/ctecorr_darks'\n",
    "# -l|--cal_dir = '/user/lprichard/hst_wfc3_uvis_reduction/darks_data/st_calib'\n",
    "# -i|--iref_dir = '/grp/hst/cdbs/iref'   #same as default OR '/user/lprichard/hst_wfc3_uvis_reduction/red_dir_lp/myref/'\n",
    "\n",
    "# Set the following flags which will set each to ``True``\n",
    "# -c|--ctecorr\n",
    "# -p|--postflash\n",
    "# -f|--fitpix    \n",
    "# *******************************************************************************\n",
    "\n",
    "# Move into codes directory and start screen, should take ~1hour depending on processing power\n",
    "# cd /user/lprichard/hst_wfc3_uvis_reduction/darks_codes/lp_darks/cal_uvis_make_darks\n",
    "# screen -S darks\n",
    "        \n",
    "# Use the following command in a terminal, the \"mode\" and \"now\" definitions ahead are for the log \n",
    "# name that the terminal output is piped to which is called at the end. \"pdb\" ipython command is for debugging.\n",
    "mode=\"dev\" && now=$(date +\"%m_%d_%Y\") && ipython --pdb -c \"%run cal_uvis_make_darks.py -a '20190319-20:37:35' \\\n",
    "    -e '20190417-11:24:51' -c -p -m '$mode' -r '/user/lprichard/hst_wfc3_uvis_reduction/darks_data/red_darks' \\\n",
    "    -d '/user/lprichard/hst_wfc3_uvis_reduction/darks_data/raw_darks/2019Mar19anneal_rawdarks_aquery2019Aug13/ctecorr_darks' \\\n",
    "    -l '/user/lprichard/hst_wfc3_uvis_reduction/darks_data/st_calib' -i '/grp/hst/cdbs/iref' -f\" \\\n",
    "    2>&1 | tee /user/lprichard/hst_wfc3_uvis_reduction/darks_codes/lp_darks/logs/log_inputtest_$now.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________\n",
    "# Copying and Delivering Darks\n",
    "\n",
    "**10) Copy darks to the combined superdark directory**\n",
    "\n",
    "If it doesn't exist (it should be created automatically in `cal_uvis_make_darks.py`), the following example code makes a `superdarks/` directory in the reduction directory e.g., `darks_data/red_darks/` for a combined directory of all the superdarks. It then copies the superdarks from a specified anneal cycle directory (made by `cal_uvis_make_darks.py` in the previous step) to that directory. The anneal cycle directory has the following form: `post-anneal-<anneal_date:YYYYMMDD>_procd-<process_date:YYYYMMDD>_<flags>/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "# ------------------------------\n",
    "# INPUTS\n",
    "#These should be set by the user\n",
    "RED_DIR = '/user/lprichard/hst_wfc3_uvis_reduction/darks_data/red_darks'  #General reduction directory containing the anneal directories\n",
    "ANN_DIR = os.path.join(RED_DIR, 'post-anneal-20190319_procd-20190910_ctecorr_dev_fitpix')    #Anneal directory from which superdarks should be copied\n",
    "\n",
    "# These shouldn't require editing if the above file structure is the same\n",
    "PDARK_DIR = os.path.join(ANN_DIR, 'masterdark_create')  #This is the standard processed darks directory made by the pipeline\n",
    "SDARK_DIR = os.path.join(RED_DIR, 'superdarks')         #Location of master superdark directory, this is made is cal_uvis_make_darks.py but checked for and made below if it doesn't exist\n",
    "# ------------------------------\n",
    "\n",
    "# Check for the superdark combined directory and make if it doesn't exist\n",
    "if os.path.exists(SDARK_DIR):\n",
    "    print('Superdark directory exists:', SDARK_DIR)\n",
    "else:\n",
    "    os.makedirs(SDARK_DIR, 0o774)\n",
    "    print('Created superdark directory:', SDARK_DIR)\n",
    "\n",
    "# Move to the processed superdark directory\n",
    "os.chdir(PDARK_DIR)\n",
    "\n",
    "# Copies superdarks out of the processed data directory to the superdarks/ directory if it doesn't exist\n",
    "n=0\n",
    "for sdark in glob.glob('d*_drk.fits'):\n",
    "    # Define source and desitnation paths for each superdark\n",
    "    src = os.path.join(PDARK_DIR, sdark)   #Source filepath of superdark to be copied\n",
    "    dst = os.path.join(SDARK_DIR, sdark)   #Destination filepath of superdark to be copied\n",
    "    \n",
    "    # Check if the superdark is already in the superdarks/ combined directory, if not it is copied\n",
    "    if not os.path.exists(dst):\n",
    "        shutil.copy(src, dst)\n",
    "        print('Copied {} to {}'.format(src, dst))\n",
    "        n+=1\n",
    "    else: \n",
    "        print('File exists {}, not copying superdark from {}'.format(dst, PDARK_DIR))\n",
    "    \n",
    "print('Copied {} files to combined superdark directory {}'.format(n, SDARK_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11) Update the dark_lookup.txt file**\n",
    "\n",
    "For processing your data using these darks, a reference table (`dark_lookup.txt`) is needed to identify which files to use. The following code reads in the current dark_lookup.txt file (**create a blank one if it doesn't yet exist**) and updates it with any new superdarks (names and useafter date) in the combined superdarks directory. It saves it to a specified output `dark_lookup.txt` file which can be the same as the input.\n",
    "\n",
    "The input dark_lookup.txt file should have `|` delimiters and contain: superdark name (e.g. `d190320201_drk.fits`), and useafter dates (in long form e.g. `Mar 19 2019 20:37:35`, and MJD `58561.85943287037`) per row. \n",
    "\n",
    "Below is code to update the `dark_lookup.txt` file with options to set if the MJD useafter date is not listed in the input file (`calc_mjd=True`), and an overwrite option to overwrite existing filenames in the file (shouldn't need to overwrite usually). To save the output file, set `writef=True`, if `False` the combined output will be printed but the file not updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from astropy.io.fits import getheader\n",
    "from pdb import set_trace as st\n",
    "from astropy.time import Time\n",
    "from datetime import datetime as dt\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------------------\n",
    "# INPUTS\n",
    "# Location of the copied superdarks, no trailing \"/\"\n",
    "RED_DIR = '/user/lprichard/hst_wfc3_uvis_reduction/darks_data/red_darks'\n",
    "SDARK_DIR = os.path.join(RED_DIR, 'superdarks')\n",
    "# The location of the input dark_lookup.txt file, should have '|' delimeters\n",
    "infile = '/user/lprichard/hst_wfc3_uvis_reduction/darks_codes/lp_darks/ref_files/dark_lookup.txt'\n",
    "# The location of the output dark_lookup.txt file (can be the same as the input), will have filename, useafter date in long form and in MJD, and '|' delimeters\n",
    "outfile = '/user/lprichard/hst_wfc3_uvis_reduction/darks_codes/lp_darks/ref_files/dark_lookup.txt'\n",
    "\n",
    "# If the infile does not have a useafter MJD column, set this to True to calculate one\n",
    "calc_mjd = False\n",
    "# Set overwrite to 'False' if you don't want to replace entries for superdarks already listed in dark_lookup.txt\n",
    "overwrite = False\n",
    "# If wanting to write the output file, set to 'True', otherwise the output will be printed but not saved to a file\n",
    "writef = True\n",
    "# ---------------------------\n",
    "\n",
    "# Read in the input dark_lookup.txt\n",
    "# If no useafter_mjd column exists, make one\n",
    "if calc_mjd==True:\n",
    "    df_in = pd.read_csv(infile, names='superdark useafter'.split(), delimiter='|')\n",
    "\n",
    "    # Convert useafter dates to MJD for old file format\n",
    "    uain_mjds = []\n",
    "    for i, ua_in in enumerate(df_in['useafter']):\n",
    "        date = dt.strptime(ua_in, '%b %d %Y %H:%M:%S')\n",
    "        iso = date.strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "        uain_mjds.append(Time(iso, format='iso').mjd)\n",
    "\n",
    "    # Add new column to the input file for MJD\n",
    "    df_in['useafter_mjd'] = uain_mjds\n",
    "    \n",
    "# If a useafter_mjd column exists, read in file as is\n",
    "else:\n",
    "    df_in = pd.read_csv(infile, names='superdark useafter useafter_mjd'.split(), delimiter='|')\n",
    "    \n",
    "# Move to the directory with the copied superdarks\n",
    "os.chdir(SDARK_DIR)    \n",
    "\n",
    "# Starting arrays for inputs of new superdakrs\n",
    "filenames = []\n",
    "useafters = []\n",
    "useafter_mjds = []\n",
    "\n",
    "# For each new superdark, get the filenames, useafter dates from header and calculate an MJD useafter date\n",
    "n=0\n",
    "for f in glob.glob('d*_drk.fits'):\n",
    "\n",
    "    # Check if the superdark is already listed in the dark_lookup.txt file\n",
    "    if not df_in['superdark'].str.contains(f).any() and (overwrite==False):\n",
    "        \n",
    "        print('Adding {} to dark_lookup.txt'.format(f))\n",
    "        \n",
    "        # Read in superdark header\n",
    "        hdr = getheader(f)\n",
    "\n",
    "        # Converting useafter date to MJD to sort\n",
    "        useafter = hdr['USEAFTER']\n",
    "        date = dt.strptime(useafter, '%b %d %Y %H:%M:%S')\n",
    "        iso = date.strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "        mjd = Time(iso, format='iso').mjd\n",
    "\n",
    "        # Storing values for each superdark\n",
    "        filenames.append(f)\n",
    "        useafters.append(useafter)\n",
    "        useafter_mjds.append(mjd)\n",
    "        \n",
    "        n+=1\n",
    "    else:\n",
    "        print('{} already listed in dark_lookup.txt, not overwriting entry'.format(f))\n",
    "\n",
    "# Store new superdark values in a data frame\n",
    "df_new = pd.DataFrame({})\n",
    "df_new['superdark'] = filenames\n",
    "df_new['useafter'] = useafters\n",
    "df_new['useafter_mjd'] = useafter_mjds\n",
    "\n",
    "# Combine the old and new dark_lookup data frames\n",
    "df_out = pd.concat([df_in, df_new])\n",
    "\n",
    "# Remove duplicates if they exist in the combined data frame by superdark filename\n",
    "df_out.drop_duplicates(subset =\"superdark\", keep = \"first\", inplace = True)\n",
    "\n",
    "# Sort the combined data frame based on useafter MJD date\n",
    "df_out = df_out.sort_values(by=['useafter_mjd']).reset_index(drop=True)\n",
    "\n",
    "print(df_out)\n",
    "print('Added {} new superdarks to {}'.format(n, outfile))\n",
    "\n",
    "# Save the new dark_lookup.txt file to the specified output file (can be the same as input) with delimeter '|'\n",
    "if writef==True:\n",
    "    print('Writing to', outfile)\n",
    "    df_out.to_csv(outfile, index=False, sep='|', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If required**\n",
    "\n",
    "Create a map of all raw dark file IDs that went into making each superdark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from astropy.io.fits import getheader\n",
    "from pdb import set_trace as st\n",
    "\n",
    "# ---------------------------\n",
    "# INPUT, NO trailing \"/\"\n",
    "RED_DIR = '/user/lprichard/hst_wfc3_uvis_reduction/darks_data/red_darks'\n",
    "SDARK_DIR = os.path.join(RED_DIR, 'superdarks')\n",
    "write_map = True\n",
    "# ---------------------------\n",
    "\n",
    "# Move to the download directory\n",
    "os.chdir(SDARK_DIR)\n",
    "\n",
    "# Defining the output filename above where the superdarks are kept\n",
    "outfile = os.path.join(os.path.split(SHARE_DIR)[0], 'superdark_idmap.txt')\n",
    "print('Writing to', outfile)\n",
    "if write_map==True: file = open(outfile, \"w\")\n",
    "\n",
    "if write_map==True: \n",
    "    # Writing ID map file pre-amble\n",
    "    file.write('# Superdark raw input file ID map saved to' + '\\n')\n",
    "    file.write('# ' + outfile + '\\n')\n",
    "    file.write('# The parent directory has the following format:' + '\\n') \n",
    "    file.write('# post-anneal-[anneal date YYYYMMDD]_procd-[processed date YYYYMMDD]_[reduction method]' + '\\n')\n",
    "    file.write('# Each superdark in the following directory (d*_drk.fits) was made of the raw IDs' + '\\n') \n",
    "    file.write('# listed below each superdark in this file, info also in each superdark header' + '\\n')\n",
    "    file.write('# ' + SHARE_DIR + '\\n')\n",
    "\n",
    "# For each superdark, get input raws from header and print\n",
    "for f in glob.glob('*'):\n",
    "    # The superdark name\n",
    "    print(\"superdark: \", f)\n",
    "    if write_map==True: file.write(f + '\\n')\n",
    "    \n",
    "    # Read in superdark header\n",
    "    hdr = getheader(f)\n",
    "    # get USEAFTER date\n",
    "    print(\"USEAFTER =\", hdr['USEAFTER'])\n",
    "    if write_map==True: file.write(\"USEAFTER = \" + hdr['USEAFTER'] + '\\n') \n",
    "    \n",
    "    # The raw ID names\n",
    "    hist = hdr['HISTORY']\n",
    "    print(\"raw IDs:\") \n",
    "    for i, ht in enumerate(hist):\n",
    "        if ('id' in hist[i]) and (' ' not in ht):\n",
    "            print(ht)\n",
    "            if write_map==True: file.write(ht + '\\n')\n",
    "            \n",
    "if write_map==True: file.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________\n",
    "____________\n",
    "____________\n",
    "____________\n",
    "____________\n",
    "\n",
    "# Download and CTE Correct Science Data\n",
    "\n",
    "**12) Set up the science data directories**\n",
    "\n",
    "Outside of the `hst_wfc3_uvis_reduction/` parent directory, set a science data directory, a project specific one will be made, this is just the parent directory for all science data. The following sets and makes example directories, e.g.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Setting path names\n",
    "SCI_ROOT = \"/user/lprichard/project\"         #EDIT! Root directory for a whole science progam\n",
    "DAT_DIR = os.path.join(SCI_ROOT, 'sci_data')      #Location of the science data both raw and reduced\n",
    "RAW_DIR = os.path.join(DAT_DIR, 'raw_sci')        #Raw science data directory\n",
    "RED_DIR = os.path.join(DAT_DIR, 'red_sci')        #Reduced science data directory\n",
    "\n",
    "print('SCI_ROOT =', SCI_ROOT)\n",
    "print('DAT_DIR =', DAT_DIR)\n",
    "print('RAW_DIR =', RAW_DIR)\n",
    "print('RED_DIR =', RED_DIR)\n",
    "\n",
    "# Making data directories if they don't exist\n",
    "if not os.path.exists(DAT_DIR): \n",
    "    os.makedirs(DAT_DIR, 0o774)\n",
    "if not os.path.exists(RAW_DIR): \n",
    "    os.makedirs(RAW_DIR, 0o774)\n",
    "if not os.path.exists(RED_DIR): \n",
    "    os.makedirs(RED_DIR, 0o774)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**13) Download the raw data files with astroquery**\n",
    "\n",
    "Get the proposal ID for the data (e.g., from MAST https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html). Then use `hst_wfc3_uvis_reduction/darks_codes/lp_darks/download_data.py` to download the science data and do file organization as for Step 5 with the darks, but now with different inputs for the science data. The code makes directories, downloads data with astroquery and sorts raw science data files ready for CTE corrections. Run using the following command in `hst_wfc3_uvis_reduction/darks_codes/lp_darks/`:\n",
    "\n",
    "        python download_data.py [-t|--type] [-s|--data_start] [-e|--data_end] [-p|--proposal_id] [-r|--raw_dir] [-d|--download] [-l|--dload_date]\n",
    "        \n",
    "For the science data, ``--type='science'`` and ``--proposal_id`` should be set. If wanting to select files from part of a proprosal (e.g. a large or ongoing program), you can also set the ``--data_start`` and ``--data_end`` dates along with the required ``--proposal_id``. These must be in MJD, all files up to but **NOT INCLUDING** the end date are selected. Can set today's date as the end date using the code below. **UPDATE April 2020: use astroquery to get the dates (example in the first cell below) as data start times are slightly different between MAST and astroquery. Files will be missed with an astroquery command and MAST start time**.\n",
    "\n",
    "Execution of this script will create the following file tree:\n",
    "\n",
    "    PID<proposal_id>_rawdata_aquery<download_date:YYYYMonDD>/\n",
    "        ctecorr_sci/       (for CTE corrected data)\n",
    "        mastDownload/HST/  (created by the astroquery download command)    \n",
    "            id**/          (creates ID specific folders with the files in)\n",
    "        raw_sci/           (for raw data copied from the download directory into a single directory)\n",
    "        calwf3_sci/        (for processing science data with new darks with calwf3)\n",
    "\n",
    "For convenience, the code below produces a readable table of data and times for a project ID (PID) from astroquery, the cell below allows you to input a calendar date and returns the MJD date that it corresponds with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for the files, ASNs and the start times with astroquery rather than taking them from MAST\n",
    "\n",
    "from astroquery.mast import Observations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from astropy.time import Time\n",
    "\n",
    "# ---------------------------------\n",
    "# INPUTS\n",
    "# Proposal ID\n",
    "PID = '12345'\n",
    "# ---------------------------------\n",
    "\n",
    "def mjd_to_str(t):\n",
    "    \"\"\"Converts Modified Julien Date (MJD) input (t) \n",
    "    to a readable date string (t_str).\"\"\"\n",
    "    t_mjd = Time(t, format='mjd')\n",
    "    t_str = t_mjd.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    return t_str\n",
    "\n",
    "# Select all science observations for the proposal ID \n",
    "sciobs = Observations.query_criteria(intentType='science', instrument_name=\"WFC3/UVIS\", proposal_id='{}'.format(PID))\n",
    "# See available columns in the result\n",
    "print(sciobs.columns)\n",
    "\n",
    "# Convert astropy table to a dataframe for manipulation\n",
    "so_df = pd.DataFrame(np.array(sciobs))\n",
    "\n",
    "# Get the easily readable date string from the MJD dates\n",
    "so_df['t_min_str'] = so_df['t_min'].apply(mjd_to_str)\n",
    "so_df['t_max_str'] = so_df['t_max'].apply(mjd_to_str)\n",
    "\n",
    "# Print just the ASN numbers (obs_id), start and end times (t_min, t_max) in MJD and string form in descending date order\n",
    "so_df[['obs_id','t_min','t_min_str','t_max','t_max_str']].sort_values('t_min', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.time import Time\n",
    "from datetime import datetime as dt\n",
    "\n",
    "# ---------------------------------\n",
    "# Start and end dates copied from the \"Start Time\" column from MAST\n",
    "# All files up to but NOT INCLUDING the end_date are selected\n",
    "start_date = '2019-03-21 05:07:16'\n",
    "end_date = '2019-04-10 18:12:42'\n",
    "# ---------------------------------\n",
    "\n",
    "# Determine the MJD for now\n",
    "now = Time(Time.now(), format='iso').mjd\n",
    "print('MJD Now:', now)\n",
    "\n",
    "# Convert these to MJD\n",
    "start_mjd = Time(start_date, format='iso').mjd\n",
    "end_mjd = Time(end_date, format='iso').mjd\n",
    "\n",
    "print('MJD start:', start_mjd)\n",
    "print('MJD end:', end_mjd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of running download_data.py from the command line using sample inputs for science raw files: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ************************************************************\n",
    "# Example of inputs\n",
    "# -t|--type = 'science'\n",
    "# -p|--proposal_id = '12345'\n",
    "# -r|--raw_dir = '/user/lprichard/project/sci_data/raw_sci'\n",
    "\n",
    "# Set the following flag which will set download to ``True``\n",
    "# -d|--download\n",
    "# OTHERWISE set dload_date to point to a directory of data downloaded on this date to do just the file organization and copying\n",
    "# -l|--dload_date = '2019Sep13'\n",
    "# ************************************************************\n",
    "\n",
    "# Move into codes directory and start screen\n",
    "# cd /user/lprichard/hst_wfc3_uvis_reduction/darks_codes/lp_darks\n",
    "# screen -S sci_dload\n",
    "\n",
    "# Use the following command in a terminal, the \"now\" definition is for the log that the terminal\n",
    "# output is piped to which is called at the end. \"pdb\" ipython command is for debugging.\n",
    "# Set to download\n",
    "now=$(date +\"%m_%d_%Y\") && ipython --pdb -c \"%run download_data.py  -t 'science' -p '12345'\\\n",
    "    -r '/user/lprichard/project/sci_data/raw_sci' -d\" 2>&1 | tee /user/lprichard/hst_wfc3_uvis_reduction/darks_codes/lp_darks/logs/log_sciaquery_$now.txt\n",
    "# OR for file organization of downloaded data\n",
    "now=$(date +\"%m_%d_%Y\") && ipython --pdb -c \"%run download_data.py  -t 'science' -p '12345'\\\n",
    "    -r '/user/lprichard/project/sci_data/raw_sci' -l '2019Sep13'\" 2>&1 | tee /user/lprichard/hst_wfc3_uvis_reduction/darks_codes/lp_darks/logs/log_sciaquery_$now.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**14) CTE correct the science data**\n",
    "\n",
    "____________________________\n",
    "NOTE: The following method is based on an old CTE correction code. As of Feb 2020, STScI are testing a new CTE correction code. Check back to the GitHub repository or the STScI website for updates prior to running this step in case this new code has been released.\n",
    "____________________________\n",
    "\n",
    "Then need to CTE correct the science data, this is done using `hst_wfc3_uvis_reduction/darks_codes/lp_darks/ctecorr_scidata.py` which is an adapted version of `cal_uvis_make_ctecorr_darks.py` that checks, copies and CTE corrects the science data. It is called using the following command:\n",
    "\n",
    "    python ctecorr_scidata.py [-c|--ctecorr_dir] [-r|--rwd_dir] [-s|--software_dir]\n",
    "\n",
    "Required:\n",
    "\n",
    "    -c|--ctecorr_dir -- String, path to output CTE corrected data directory made in download_data.py, no trailing slash \"/\".\n",
    "\n",
    "    -r|--rwd_dir -- String, path to raw data directory (all files in one folder as done in previous step with download_data.py), no trailing slash \"/\".\n",
    "\n",
    "    -s|--software_dir -- String, path to the compiled CTE correction code ./wfc3uv_ctereverse.e, no trailing slash \"/\".\n",
    "\n",
    "An example of running ctecorr_scidata.py from the command line using sample inputs: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *******************************************************************************\n",
    "# Example of inputs\n",
    "# -c|--ctecorr_dir = '/user/lprichard/project/sci_data/raw_sci/PID12345_rawdata_aquery2019Sep13/ctecorr_sci'\n",
    "# -r|--rwd_dir = '/user/lprichard/project/sci_data/raw_sci/PID12345_rawdata_aquery2019Sep13/raw_sci'\n",
    "# -s|--software_dir = '/user/lprichard/software' \n",
    "# *******************************************************************************\n",
    "\n",
    "# Move into codes directory and start screen\n",
    "# cd /user/lprichard/hst_wfc3_uvis_reduction/darks_codes/lp_darks\n",
    "# screen -S ctesci\n",
    "\n",
    "# Use the following command in a terminal, the \"now\" definition ahead is for the log  that the \n",
    "# terminal output is piped to which is called at the end. \"pdb\" ipython command is for debugging.\n",
    "now=$(date +\"%m_%d_%Y\") && ipython --pdb -c \"%run ctecorr_scidata.py  -c '/user/lprichard/project/sci_data/raw_sci/PID12345_rawdata_aquery2019Sep13/ctecorr_sci'\\\n",
    "    -r '/user/lprichard/project/sci_data/raw_sci/PID12345_rawdata_aquery2019Sep13/raw_sci' \\\n",
    "    -s '/user/lprichard/software'\" 2>&1 | tee /user/lprichard/hst_wfc3_uvis_reduction/darks_codes/lp_darks/logs/log_ctecorrPID12345_$now.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________\n",
    "# Process Science Data with New Darks\n",
    "\n",
    "**15) Select which superdarks to use for the science data**\n",
    "\n",
    "For the CTE corrected science data files, the following code cross-references the superdarks listed in `dark_lookup.txt` that are within the `superdarks/` directory to find which superdarks to use to process the data. It creates two files within the CTE correction science data directory:\n",
    "\n",
    "    file_summary.txt -- a list of the science data raw file names, date of the observations, exposure start time in MJD, and the superdark to use for each raw science file\n",
    "    superdarks.txt -- is a comma separated version of dark_lookup.txt at the time of running the below code\n",
    "    \n",
    "If not all science data files have a corresponding superdark, a warning is given and the output files are **not saved**. You must therefore make sure you have the relevant superdarks for the science data, that these have been moved to the `superdarks/` directory, and that the `dark_lookup.txt` has been updated to reflect the `superdarks/` directory. You must have the saved `file_summary.txt` file to proceed to the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Written by Ben Sunquist, adapted by Laura Prichard\n",
    "# see what dark to use in calwf3 for each file\n",
    "\n",
    "from astropy.time import Time\n",
    "from datetime import datetime as dt\n",
    "import astropy.io.fits as fits\n",
    "import numpy as np\n",
    "from pdb import set_trace as st\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# ----------------------------------\n",
    "# INPUT\n",
    "CTECORR_DIR = '/user/lprichard/project/sci_data/raw_sci/PID12345_rawdata_aquery2019Sep13/ctecorr_sci'\n",
    "DARK_LOOKUP = '/user/lprichard/hst_wfc3_uvis_reduction/darks_codes/lp_darks/ref_files/dark_lookup.txt'\n",
    "# ----------------------------------\n",
    "\n",
    "# get info for rac files\n",
    "files = glob.glob(os.path.join(CTECORR_DIR, '*rac.fits'))\n",
    "times = []\n",
    "expstarts = []\n",
    "filenames = []\n",
    "files_raw = []\n",
    "for f in files:\n",
    "    filenames.append(os.path.basename(f))\n",
    "    files_raw.append(os.path.basename(f).replace('rac','raw'))\n",
    "    info = '{} {}'.format(fits.getheader(f,0)['DATE-OBS'], fits.getheader(f,0)['TIME-OBS'])\n",
    "    times.append(info)\n",
    "    expstarts.append(fits.getheader(f,0)['EXPSTART'])\n",
    "\n",
    "# Save rac file info to data frame\n",
    "df = pd.DataFrame({})\n",
    "df['file'] = filenames\n",
    "df['file_raw'] = files_raw\n",
    "df['date'] = times\n",
    "df['expstart'] = expstarts\n",
    "df = df.sort_values(by=['expstart']).reset_index(drop=True)\n",
    "\n",
    "# get info for superdarks\n",
    "df_sd = pd.read_csv(DARK_LOOKUP, names='superdark useafter useafter_mjd'.split(), delimiter='|')\n",
    "df_sd = df_sd.sort_values(by=['useafter_mjd']).reset_index(drop=True)\n",
    "\n",
    "# add superdark to use to df for each file\n",
    "sds = []\n",
    "t = np.array(df_sd['useafter_mjd'])\n",
    "n=0\n",
    "for i in range(len(df)):\n",
    "    expstart = float(df['expstart'][i])\n",
    "    if len(np.where(expstart>t)[0])>0:\n",
    "        sd_match = df_sd['superdark'].iloc[np.where(expstart>t)[0][-1]]\n",
    "        n+=1\n",
    "    else:\n",
    "        sd_match = ''\n",
    "        print('There is no superdark for science data file {} with start time {}'.format(df['file'][i], df['expstart'][i]))\n",
    "    sds.append(sd_match)\n",
    "\n",
    "df['superdark'] = sds\n",
    "\n",
    "# Check if all the raw files have a superdark, if so saving the output files, if not print warning\n",
    "if n==len(df):\n",
    "    print('All raw science data files were matched to a superdark')\n",
    "    df.to_csv(os.path.join(CTECORR_DIR, 'file_summary.txt'), index=False)\n",
    "    df_sd.to_csv(os.path.join(CTECORR_DIR, 'superdarks.txt'), index=False)\n",
    "else: \n",
    "    print('WARNING: There are not superdarks for all of the raw science data, output not saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**16) Move science data to processing directory**\n",
    "\n",
    "The processing directory is where all the science data and the relevant superdarks will be moved to, to run calwf3. This process also involves renaming files and updating header information so that calwf3 can run normally on them without factoring in the previous reduction stages that have been changed from the standard procedure.\n",
    "\n",
    "The code below moves and renames the `*rac.fits` files to `*raw.fits` files from the user-defined CTE correction directory into the user-defined processing directory if the file doesn't already exist. These directories are both within the same proposal ID directory and are made in Step 13 by `download_data.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the science data *rac.fits files into a new directory, then rename to *raw.fits so that calwf3 can run on them\n",
    "# ----------------------------------\n",
    "# INPUT\n",
    "CTECORR_DIR = '/user/lprichard/project/sci_data/raw_sci/PID12345_rawdata_aquery2019Sep13/ctecorr_sci'\n",
    "PROC_DIR = '/user/lprichard/project/sci_data/raw_sci/PID12345_rawdata_aquery2019Sep13/calwf3_sci'\n",
    "# ----------------------------------\n",
    "\n",
    "# Check for the superdark combined directory and make if it doesn't exist\n",
    "if os.path.exists(PROC_DIR):\n",
    "    print('Directory to process data in exists:', PROC_DIR)\n",
    "else:\n",
    "    os.makedirs(PROC_DIR, 0o774)\n",
    "    print('Created directory to process data in:', PROC_DIR)\n",
    "\n",
    "# Move to the processed superdark directory\n",
    "os.chdir(CTECORR_DIR)\n",
    "\n",
    "# Copies science data *rac.fits files out of the CTE correction directory to the superdarks/ directory if it doesn't exist\n",
    "n=0\n",
    "for rac in glob.glob('*rac.fits'):\n",
    "    # Define source and desitnation paths for each superdark\n",
    "    src = os.path.join(CTECORR_DIR, rac)   #Source filepath of rac file to be copied\n",
    "    dst = os.path.join(PROC_DIR, rac.replace('rac','raw'))   #Destination filepath of rac to be copied and renamed\n",
    "    \n",
    "    # Check if the superdark is already in the superdarks/ combined directory, if not it is copied\n",
    "    if not os.path.exists(dst):\n",
    "        shutil.copy(src, dst)\n",
    "        print('Copied {} to {}'.format(src, dst))\n",
    "        n+=1\n",
    "    else: \n",
    "        print('File {} exists, not copying file from {}'.format(dst, CTECORR_DIR))\n",
    "    \n",
    "print('Copied {} rac.fits files to the directory {} to be processed by calwf3'.format(n, PROC_DIR))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**17) Move superdarks to processing directory**\n",
    "\n",
    "Again, using information from the `file_summary.txt` file produced in Step 15, copy the superdarks necessary to process the science data into the processing directory if they don't already exist there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# ----------------------------------\n",
    "# INPUT\n",
    "CTECORR_DIR = '/user/lprichard/project/sci_data/raw_sci/PID12345_rawdata_aquery2019Sep13/ctecorr_sci'\n",
    "PROC_DIR = '/user/lprichard/project/sci_data/raw_sci/PID12345_rawdata_aquery2019Sep13/calwf3_sci'\n",
    "RED_DIR = '/user/lprichard/hst_wfc3_uvis_reduction/darks_data/red_darks'\n",
    "SDARK_DIR = os.path.join(RED_DIR, 'superdarks')\n",
    "# ----------------------------------\n",
    "\n",
    "# Read in the file made previously for the data in the processing directory\n",
    "df = pd.read_csv(os.path.join(CTECORR_DIR,'file_summary.txt'))\n",
    "\n",
    "n=0\n",
    "# For each superdark required for the data, copy it to the processing directory if it doesn't exist\n",
    "for sd in df['superdark'].unique():\n",
    "    \n",
    "    # Define source and desitnation paths for each superdark\n",
    "    src = os.path.join(SDARK_DIR, sd)   #Source filepath of rac file to be copied\n",
    "    dst = os.path.join(PROC_DIR, sd)   #Destination filepath of rac to be copied and renamed\n",
    "    \n",
    "    # Check if the superdark is already in the superdarks/ combined directory, if not it is copied\n",
    "    if not os.path.exists(dst):\n",
    "        shutil.copy(src, dst)\n",
    "        print('Copied {} to {}'.format(src, dst))\n",
    "        n+=1\n",
    "    else: \n",
    "        print('File exists {}, not copying superdark from {}'.format(dst, SDARK_DIR))\n",
    "    \n",
    "print('Copied {} superdarks to the directory {} to be processed by calwf3'.format(n, PROC_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**18) Update headers of darks and science data to point to current best standard reference files**\n",
    "\n",
    "Use `crds.bestrefs` (https://hst-crds.stsci.edu/static/users_guide/command_line_tools.html) to automatically update the reference files in the headers to the current best files. Do this **before** setting any custom header keywords below.\n",
    "\n",
    "From `prep_header_keys.py` in the darks pipline where `crds.bestrefs` is used:\n",
    "    \"In order for the ``crds.bestrefs.BestrefsScript`` to run, the\n",
    "        following environments must be configured:\n",
    "\n",
    "            setenv CRDS_PATH /grp/crds/cache\n",
    "            setenv CRDS_SERVER_URL https://hst-crds.stsci.edu\n",
    " ...The ``FLSHFILE`` must also be set for postflash\n",
    "        correction (if necessary).  However, as to avoid hardcoding the file in\n",
    "        the script, the ``crds.bestrefs`` routine is used to determine the best\n",
    "        postflash reference file to use.\"\n",
    "        \n",
    "Set the iref environement if not already set:\n",
    "    \n",
    "    e.g., export iref=\"/grp/hst/cdbs/iref/\"\n",
    "    \n",
    "If you don't have access to this iref/ directory, get the iref/ files needed from STScI and point to that local directory: http://www.stsci.edu/itt/review/2008_HST_Docs/WFC3_DHB/wfc3_Ch53.html#63144 (use Safari or other browser if not working on Chrome)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_bestrefs(image_list, key='', update=True):\n",
    "    \"\"\"From prep_header_keys.py written by Matt Bourque adapted by Laura Prichard.\n",
    "    Don't set `key` if you want all reference files to be updated or for a specific file,\n",
    "    set `key` to the header keyword for which you want the best reference file: \n",
    "    e.g. ``FLSHFILE`` forthe best postflash reference file, ``BIASFILE`` for best bias.\n",
    "    Set update=True to update the headers, or update=False to print the reference files \n",
    "    that will be updated.\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_list : list\n",
    "        The list of absolute paths to the images to update.\n",
    "    key : str\n",
    "        Header key word to update. If not set, all refernece files will be updated.\n",
    "    update : bool\n",
    "        Set to True to update the reference files in the header, \n",
    "        False to print out the current and replacement reference files\n",
    "    \"\"\"\n",
    "    # Check if the header keyword has been set\n",
    "    if key=='':\n",
    "        # Find and update the headers with the best reference file\n",
    "        images = ' '.join(image_list)\n",
    "        \n",
    "        # Updating or just printing those that will be updated\n",
    "        if update==True: \n",
    "            print('Updating all reference files with bestrefs')\n",
    "            bestrefs_arg = \"crds.bestrefs  --update-bestrefs --files {} --verbosity 0\".format(images, key)\n",
    "        else: \n",
    "            print('Will update the following reference files if update=True')\n",
    "            bestrefs_arg = \"crds.bestrefs --print-new-references --files {}\".format(images)\n",
    "        \n",
    "        script = BestrefsScript(argv=bestrefs_arg)\n",
    "        script.run()\n",
    "    else:\n",
    "        # Find and update the headers with the best reference file\n",
    "        images = ' '.join(image_list)\n",
    "        \n",
    "        if update==True:\n",
    "            print('Updating {} reference file'.format(key))\n",
    "            bestrefs_arg = \"crds.bestrefs  --update-bestrefs --files {} --types {} --verbosity 0\".format(images, key)\n",
    "        else: \n",
    "            print('Will update the following {} reference file if update=True'.format(key))\n",
    "            bestrefs_arg = \"crds.bestrefs --print-new-references --files {} --types {}\".format(images)\n",
    "        script = BestrefsScript(argv=bestrefs_arg)\n",
    "        script.run()\n",
    "\n",
    "def print_hdr_keys(image_list, key=''):\n",
    "    \"\"\"Prints reference files in a *raw.fits/*rac.fits or other HST file if `key` not set\n",
    "    or any specifified header key word (`key` str) for a list of images.\n",
    "    \n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    image_list : list\n",
    "        The list of absolute paths to the images to update.\n",
    "    key : str\n",
    "        Header key word to print. If not set, all reference files will be printed.\"\"\"\n",
    "    \n",
    "    for image in image_list:\n",
    "        print('File: {}'.format(image))\n",
    "\n",
    "        # Open image and get the header\n",
    "        hdul = fits.open(image)\n",
    "        hdr = hdul[0].header\n",
    "\n",
    "        if key=='':\n",
    "            print('---------------------------------------')\n",
    "            print('Reference files for {}:'.format(os.path.basename(image)))\n",
    "            keys = ['ATODTAB', 'BIACFILE', 'BIASFILE', 'BPIXTAB', 'CCDTAB', 'CRREJTAB', 'D2IMFILE', 'DARKFILE', 'DRKCFILE', 'FLSHFILE', \\\n",
    "            'IDCTAB', 'IMPHTTAB', 'MDRIZTAB', 'NLINFILE', 'NPOLFILE', 'OSCNTAB', 'PCTETAB', 'PFLTFILE', 'SNKCFILE']\n",
    "\n",
    "            for k in keys:\n",
    "                print(\"{} is {}\".format(k, hdr[k]))\n",
    "            print('---------------------------------------')\n",
    "        else:\n",
    "            # Get and update bias\n",
    "            print(\"{} is {}\".format(key, hdr[key]))\n",
    "        \n",
    "        # Save changes\n",
    "        hdul.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating the header keys with the best reference files\n",
    "from crds.bestrefs import BestrefsScript\n",
    "import os\n",
    "import glob\n",
    "import astropy.io.fits as fits\n",
    "\n",
    "# ------------------------------\n",
    "# INPUTS\n",
    "PROC_DIR = '/user/lprichard/project/sci_data/raw_sci/PID12345_rawdata_aquery2019Sep13/calwf3_sci'\n",
    "# ------------------------------\n",
    "\n",
    "# For each file in there, check the headers and update:\n",
    "image_list = glob.glob(os.path.join(PROC_DIR,'*.fits'))\n",
    "\n",
    "# Print existing reference files (or a key word) from the file headers\n",
    "print_hdr_keys(image_list)\n",
    "\n",
    "# To print reference files and any updates, set update=False, to update headers update=True\n",
    "set_bestrefs(image_list, update=False)\n",
    "\n",
    "# Print updated reference files (or a key word) from the file headers\n",
    "# print_hdr_keys(image_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**19) Update the header of the science data with custom calibration files**\n",
    "\n",
    "For each CTE corrected science file (that has been renamed to `raw` from `rac`), replace the dark file to use in the header to the relevant new superdark based on the output `file_summary.txt` file prodcued in Step 15. Also turn the CTE correction flag to `OMIT` as this has already been done separately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Written by Ben Sunquist, adapted by Laura Prichard\n",
    "# Update the headers of the science data to point to the right superdarks and run with calwf3\n",
    "\n",
    "import astropy.io.fits as fits\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# ----------------------------------\n",
    "# INPUT\n",
    "CTECORR_DIR = '/user/lprichard/project/sci_data/raw_sci/PID12345_rawdata_aquery2019Sep13/ctecorr_sci'\n",
    "PROC_DIR = '/user/lprichard/project/sci_data/raw_sci/PID12345_rawdata_aquery2019Sep13/calwf3_sci'\n",
    "# ----------------------------------\n",
    "\n",
    "# update DARKFILE headers in the rac files to the new superdarksand turn off CTE (THESE ARE ALREADY RACS, I.E. CTE CORRECTED)\n",
    "df = pd.read_csv(os.path.join(CTECORR_DIR, 'file_summary.txt'))\n",
    "\n",
    "files = glob.glob(os.path.join(PROC_DIR, '*raw.fits'))\n",
    "n=0\n",
    "for f in files:\n",
    "    h = fits.open(f)\n",
    "    sd = df['superdark'][df['file']==os.path.basename(f)].values[0]\n",
    "    h[0].header['DARKFILE'] = sd\n",
    "    h[0].header['PCTECORR'] = 'OMIT'\n",
    "    h.writeto(f, overwrite=True)\n",
    "    h.close()\n",
    "    n+=1\n",
    "    print('Updated header for {}'.format(os.path.basename(f)))\n",
    "    \n",
    "print('Updated headers for {} files ready for processing by calwf3 in {}'.format(n, PROC_DIC))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**20) Update header info of superdarks so they can run with calwf3**\n",
    "\n",
    "For the copied superdarks in the processing directory, change the `FILETYPE` key word to `DARK` so that calwf3 can run on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import astropy.io.fits as fits\n",
    "\n",
    "# ----------------------------------\n",
    "# INPUT\n",
    "PROC_DIR = '/user/lprichard/project/sci_data/raw_sci/PID12345_rawdata_aquery2019Sep13/calwf3_sci'\n",
    "# ----------------------------------\n",
    "\n",
    "# change superdark filetype to dark (so calwf3 will run)\n",
    "for f in glob.glob(os.path.join(PROC_DIR,'d*.fits')):\n",
    "    h = fits.open(f)\n",
    "    h[0].header['FILETYPE'] = 'DARK'\n",
    "    h.writeto(f, overwrite=True)\n",
    "    h.close()\n",
    "    print('Updated header for superdark {}'.format(f))\n",
    "print('Updated headers for {} superdarks ready for processing by calwf3 in {}'.format(n, PROC_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**21) Run calwf3 on data**\n",
    "\n",
    "Within the processing directory with the copied updated files, run calwf3 from the terminal using the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the terminal using the following example commands\n",
    "\n",
    "# Move into the processing directory (PROC_DIR) with the science data and renamed darks with updated headers\n",
    "cd /user/lprichard/project/sci_data/raw_sci/PID12345_rawdata_aquery2019Sep13/calwf3_sci\n",
    "\n",
    "# Set the iref environement if not already set\n",
    "export iref=\"/grp/hst/cdbs/iref/\"\n",
    "\n",
    "# Run calwf3 on each raw science file\n",
    "ls *raw.fits | awk '{print \"calwf3.e\",$1}' | csh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**22) Correct for amp offsets (produces smoother images)**\n",
    "\n",
    "This step subtracts the median background from each of the amp quadrants in the `*flt.fits` files produced by `calwf3` resulting in smoother final and Drizzled images. The median subtracted `*flt.fits` files produced by this step will be renamed `*flt_medsub.fits`. Go to the Ben Sunnquists's `make_uvis_skydark.py` GitHub page and download the latest version to the processing directory (PROC_DIR), e.g.:\n",
    "\n",
    "    cd /user/lprichard/project/sci_data/raw_sci/PID12345_rawdata_aquery2019Sep13/calwf3_sci\n",
    "    wget https://github.com/bsunnquist/uvis-skydarks/blob/master/make_uvis_skydark.py\n",
    "    \n",
    "Run the code from the terminal using the example below. Use the `--no_multiply_flat` flag for a simple median subtraction, or remove for a mediam amp value mutiplied by the flat to be subtracted (depends on data type if this is preferred). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move into PROC_DIR\n",
    "cd /user/lprichard/project/sci_data/raw_sci/PID12345_rawdata_aquery2019Sep13/calwf3_sci\n",
    "\n",
    "# Set iref/ environement if not already set\n",
    "export iref=\"/grp/hst/cdbs/iref/\"\n",
    "\n",
    "# To perform median amp subtraction \n",
    "ipython --pdb -c \"%run make_uvis_skydark.py --no_multiply_flat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**23) Rename and move files**\n",
    "\n",
    "The files produced by `calwf3` will be labeled `*flt.fits` files as it doesn't know that the files have already been CTE corrected. The files that have had the medium amp background subtracted (medsub) in step 22) with `make_uvis_skydark.py` will be labeled `*flt_medsub.fits`. Move these files to a `final/` directory and correctly change their name to `flc.fits` files. These science files are ready to be drizzled together with AstroDrizzle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY or the new CTE corrected code, make a final/ directory, copy the flts to there and rename flcs\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "# ---------------------------\n",
    "# INPUTS\n",
    "PROC_DIR = '/user/lprichard/project/sci_data/raw_sci/PID12345_rawdata_aquery2019Sep13/calwf3_sci'\n",
    "FINAL_DIR = '/user/lprichard/project/sci_data/raw_sci/PID12345_rawdata_aquery2019Sep13/calwf3_sci/final'\n",
    "# ---------------------------\n",
    "\n",
    "# Check for the processing directory and make if it doesn't exist\n",
    "if os.path.exists(FINAL_DIR):\n",
    "    print('FINAL_DIR directory exists:', FINAL_DIR)\n",
    "else:\n",
    "    os.makedirs(FINAL_DIR, 0o774)\n",
    "    print('Created FINAL_DIR directory:', FINAL_DIR)\n",
    "\n",
    "# Move to the CTE corrected science data directory\n",
    "os.chdir(PROC_DIR)\n",
    "\n",
    "# Copies science data *flt.fits files to the final directory if they don't exist and renames them to *flc.fits\n",
    "n=0\n",
    "for flt in glob.glob('*flt_medsub.fits'):\n",
    "    # Define source and destination paths for each flt file\n",
    "    src = os.path.join(PROC_DIR, flt) \n",
    "    dst = os.path.join(FINAL_DIR, flt.replace('flt_medsub','flc'))\n",
    "    \n",
    "    # Check if the flc file is already in final directory, if so it is not copied\n",
    "    if not os.path.exists(dst):\n",
    "        shutil.copy(src, dst)\n",
    "        print('Copied {} to {}'.format(src, dst))\n",
    "        n+=1\n",
    "    else: \n",
    "        print('{} exists, not copying file from {}'.format(dst, PROC_DIR))\n",
    "    \n",
    "print('Copied {} flt_medsubs and renamed to flcs to {}'.format(n, FINAL_DIR))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
